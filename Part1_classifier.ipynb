{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2e7756",
   "metadata": {},
   "source": [
    "Model fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c369b6",
   "metadata": {},
   "source": [
    "The baseline model performance(Train+Val)\n",
    "\n",
    "\n",
    "\n",
    "Fianl feature count 389\n",
    "\n",
    "Weighted validation metrics (LogReg baseline):\n",
    " - accuracy : 0.9548147958276519\n",
    " - precision: 0.7283222226373169\n",
    " - recall   : 0.4084099405205401\n",
    " - f1       : 0.5233493786271743\n",
    " - roc_auc  : 0.9442860360723193\n",
    "\n",
    "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
    " - [[32035699.94000005   318739.25      ]\n",
    " - [ 1237740.37         854486.08      ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e4ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b30e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class_of_worker",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "detailed_industry_recode",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "detailed_occupation_recode",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wage_per_hour",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "enroll_in_edu_inst_last_wk",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "marital_stat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "major_industry_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "major_occupation_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hispanic_origin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "member_of_a_labor_union",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reason_for_unemployment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "full_or_part_time_employment_stat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capital_gains",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "capital_losses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dividends_from_stocks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tax_filer_stat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "region_of_previous_residence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "state_of_previous_residence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "detailed_household_and_family_stat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "detailed_household_summary_in_household",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "migration_code_change_in_msa",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "migration_code_change_in_reg",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "migration_code_move_within_reg",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "live_in_this_house_1_year_ago",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "migration_prev_res_in_sunbelt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_persons_worked_for_employer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "family_members_under_18",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_of_birth_father",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_of_birth_mother",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_of_birth_self",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citizenship",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "own_business_or_self_employed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fill_inc_questionnaire_for_veteran_s_admin",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "veterans_benefits",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "weeks_worked_in_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2fd9d081-7f89-40be-adbe-6eb3bf46a3ec",
       "rows": [
        [
         "0",
         "73",
         "Not in universe",
         "0",
         "0",
         "High school graduate",
         "0",
         "Not in universe",
         "Widowed",
         "Not in universe or children",
         "Not in universe",
         "White",
         "All other",
         "Female",
         "Not in universe",
         "Not in universe",
         "Not in labor force",
         "0",
         "0",
         "0",
         "Nonfiler",
         "Not in universe",
         "Not in universe",
         "Other Rel 18+ ever marr not in subfamily",
         "Other relative of householder",
         "1700.09",
         "unknown",
         "unknown",
         "unknown",
         "Not in universe under 1 year old",
         "unknown",
         "0",
         "Not in universe",
         "United-States",
         "United-States",
         "United-States",
         "Native- Born in the United States",
         "0",
         "Not in universe",
         "2",
         "0",
         "95",
         "0"
        ],
        [
         "1",
         "58",
         "Self-employed-not incorporated",
         "4",
         "34",
         "Some college but no degree",
         "0",
         "Not in universe",
         "Divorced",
         "Construction",
         "Precision production craft & repair",
         "White",
         "All other",
         "Male",
         "Not in universe",
         "Not in universe",
         "Children or Armed Forces",
         "0",
         "0",
         "0",
         "Head of household",
         "South",
         "Arkansas",
         "Householder",
         "Householder",
         "1053.55",
         "MSA to MSA",
         "Same county",
         "Same county",
         "No",
         "Yes",
         "1",
         "Not in universe",
         "United-States",
         "United-States",
         "United-States",
         "Native- Born in the United States",
         "0",
         "Not in universe",
         "2",
         "52",
         "94",
         "0"
        ],
        [
         "2",
         "18",
         "Not in universe",
         "0",
         "0",
         "10th grade",
         "0",
         "High school",
         "Never married",
         "Not in universe or children",
         "Not in universe",
         "Asian or Pacific Islander",
         "All other",
         "Female",
         "Not in universe",
         "Not in universe",
         "Not in labor force",
         "0",
         "0",
         "0",
         "Nonfiler",
         "Not in universe",
         "Not in universe",
         "Child 18+ never marr Not in a subfamily",
         "Child 18 or older",
         "991.95",
         "unknown",
         "unknown",
         "unknown",
         "Not in universe under 1 year old",
         "unknown",
         "0",
         "Not in universe",
         "Vietnam",
         "Vietnam",
         "Vietnam",
         "Foreign born- Not a citizen of U S ",
         "0",
         "Not in universe",
         "2",
         "0",
         "95",
         "0"
        ],
        [
         "3",
         "9",
         "Not in universe",
         "0",
         "0",
         "Children",
         "0",
         "Not in universe",
         "Never married",
         "Not in universe or children",
         "Not in universe",
         "White",
         "All other",
         "Female",
         "Not in universe",
         "Not in universe",
         "Children or Armed Forces",
         "0",
         "0",
         "0",
         "Nonfiler",
         "Not in universe",
         "Not in universe",
         "Child <18 never marr not in subfamily",
         "Child under 18 never married",
         "1758.14",
         "Nonmover",
         "Nonmover",
         "Nonmover",
         "Yes",
         "Not in universe",
         "0",
         "Both parents present",
         "United-States",
         "United-States",
         "United-States",
         "Native- Born in the United States",
         "0",
         "Not in universe",
         "0",
         "0",
         "94",
         "0"
        ],
        [
         "4",
         "10",
         "Not in universe",
         "0",
         "0",
         "Children",
         "0",
         "Not in universe",
         "Never married",
         "Not in universe or children",
         "Not in universe",
         "White",
         "All other",
         "Female",
         "Not in universe",
         "Not in universe",
         "Children or Armed Forces",
         "0",
         "0",
         "0",
         "Nonfiler",
         "Not in universe",
         "Not in universe",
         "Child <18 never marr not in subfamily",
         "Child under 18 never married",
         "1069.16",
         "Nonmover",
         "Nonmover",
         "Nonmover",
         "Yes",
         "Not in universe",
         "0",
         "Both parents present",
         "United-States",
         "United-States",
         "United-States",
         "Native- Born in the United States",
         "0",
         "Not in universe",
         "0",
         "0",
         "94",
         "0"
        ]
       ],
       "shape": {
        "columns": 42,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>class_of_worker</th>\n",
       "      <th>detailed_industry_recode</th>\n",
       "      <th>detailed_occupation_recode</th>\n",
       "      <th>education</th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>enroll_in_edu_inst_last_wk</th>\n",
       "      <th>marital_stat</th>\n",
       "      <th>major_industry_code</th>\n",
       "      <th>major_occupation_code</th>\n",
       "      <th>...</th>\n",
       "      <th>country_of_birth_father</th>\n",
       "      <th>country_of_birth_mother</th>\n",
       "      <th>country_of_birth_self</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>own_business_or_self_employed</th>\n",
       "      <th>fill_inc_questionnaire_for_veteran_s_admin</th>\n",
       "      <th>veterans_benefits</th>\n",
       "      <th>weeks_worked_in_year</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High school graduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Self-employed-not incorporated</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Precision production craft &amp; repair</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10th grade</td>\n",
       "      <td>0</td>\n",
       "      <td>High school</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Foreign born- Not a citizen of U S</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not in universe or children</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native- Born in the United States</td>\n",
       "      <td>0</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age                 class_of_worker  detailed_industry_recode  \\\n",
       "0   73                 Not in universe                         0   \n",
       "1   58  Self-employed-not incorporated                         4   \n",
       "2   18                 Not in universe                         0   \n",
       "3    9                 Not in universe                         0   \n",
       "4   10                 Not in universe                         0   \n",
       "\n",
       "   detailed_occupation_recode                   education  wage_per_hour  \\\n",
       "0                           0        High school graduate              0   \n",
       "1                          34  Some college but no degree              0   \n",
       "2                           0                  10th grade              0   \n",
       "3                           0                    Children              0   \n",
       "4                           0                    Children              0   \n",
       "\n",
       "  enroll_in_edu_inst_last_wk   marital_stat          major_industry_code  \\\n",
       "0            Not in universe        Widowed  Not in universe or children   \n",
       "1            Not in universe       Divorced                 Construction   \n",
       "2                High school  Never married  Not in universe or children   \n",
       "3            Not in universe  Never married  Not in universe or children   \n",
       "4            Not in universe  Never married  Not in universe or children   \n",
       "\n",
       "                 major_occupation_code  ... country_of_birth_father  \\\n",
       "0                      Not in universe  ...           United-States   \n",
       "1  Precision production craft & repair  ...           United-States   \n",
       "2                      Not in universe  ...                 Vietnam   \n",
       "3                      Not in universe  ...           United-States   \n",
       "4                      Not in universe  ...           United-States   \n",
       "\n",
       "  country_of_birth_mother country_of_birth_self  \\\n",
       "0           United-States         United-States   \n",
       "1           United-States         United-States   \n",
       "2                 Vietnam               Vietnam   \n",
       "3           United-States         United-States   \n",
       "4           United-States         United-States   \n",
       "\n",
       "                           citizenship own_business_or_self_employed  \\\n",
       "0    Native- Born in the United States                             0   \n",
       "1    Native- Born in the United States                             0   \n",
       "2  Foreign born- Not a citizen of U S                              0   \n",
       "3    Native- Born in the United States                             0   \n",
       "4    Native- Born in the United States                             0   \n",
       "\n",
       "  fill_inc_questionnaire_for_veteran_s_admin  veterans_benefits  \\\n",
       "0                            Not in universe                  2   \n",
       "1                            Not in universe                  2   \n",
       "2                            Not in universe                  2   \n",
       "3                            Not in universe                  0   \n",
       "4                            Not in universe                  0   \n",
       "\n",
       "   weeks_worked_in_year  year label  \n",
       "0                     0    95     0  \n",
       "1                    52    94     0  \n",
       "2                     0    95     0  \n",
       "3                     0    94     0  \n",
       "4                     0    94     0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cff94b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (79861, 39) Val: (19966, 39) Test(95) (99696, 39)\n",
      "Train y% label\n",
      "0    0.9415\n",
      "1    0.0585\n",
      "Name: proportion, dtype: float64\n",
      "Val y% label\n",
      "0    0.9415\n",
      "1    0.0585\n",
      "Name: proportion, dtype: float64\n",
      "Test y% label\n",
      "0    0.9344\n",
      "1    0.0656\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# same train test split strategy as the previous model\n",
    "\n",
    "y = df['label']\n",
    "w = df['weight']\n",
    "\n",
    "X = df.drop(columns=['label','weight'])\n",
    "\n",
    "# build the test set\n",
    "test_mask = X['year'] == 95\n",
    "\n",
    "X_test = X.loc[test_mask].drop(columns=['year'])\n",
    "y_test = y.loc[test_mask]\n",
    "w_test = w.loc[test_mask]\n",
    "\n",
    "# build the train test\n",
    "trainval_mask = X['year'] == 94\n",
    "\n",
    "X_94 = X.loc[trainval_mask].drop(columns=[\"year\"])\n",
    "y_94 = y.loc[trainval_mask]\n",
    "w_94 = w.loc[trainval_mask]\n",
    "\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(X_94, y_94, w_94,test_size=0.2,\n",
    "                                                                  random_state=42,stratify=y_94)\n",
    "\n",
    "print('Train:',X_train.shape, 'Val:',X_val.shape,'Test(95)', X_test.shape)\n",
    "print('Train y%', y_train.value_counts(normalize=True).round(4))\n",
    "print('Val y%', y_val.value_counts(normalize=True).round(4))\n",
    "print('Test y%', y_test.value_counts(normalize=True).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833f8ed",
   "metadata": {},
   "source": [
    "Try to tune the decision to max out threshold for F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68dfeeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fianl feature count 389\n",
      "\n",
      "Weighted validation metrics (LogReg baseline):\n",
      "accuracy : 0.9548147958276519\n",
      "precision: 0.7283222226373169\n",
      "recall   : 0.4084099405205401\n",
      "f1       : 0.5233493786271743\n",
      "roc_auc  : 0.9442860360723193\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[32035699.94000005   318739.25      ]\n",
      " [ 1237740.37         854486.08      ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "numerical_col = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_col = [col for col in X_train.columns if col not in numerical_col]\n",
    "\n",
    "numerical_tran = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('sclar', StandardScaler(with_mean=False))\n",
    "])\n",
    "\n",
    "cate_tran = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',  sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num',numerical_tran,numerical_col),\n",
    "    ('cat',cate_tran,categorical_col),],\n",
    "    remainder='drop')\n",
    "\n",
    "preprocess.fit(X_train)\n",
    "n_features = preprocess.transform(X_train.iloc[:5]).shape[1]\n",
    "print('Fianl feature count', n_features)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "baseline_model = Pipeline(steps=[\n",
    "    ('preporcess',preprocess),\n",
    "    ('logreg',log_reg)\n",
    "])\n",
    "\n",
    "baseline_model.fit(X_train,y_train,logreg__sample_weight = w_train)\n",
    "\n",
    "\n",
    "proba_val = baseline_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nWeighted validation metrics (LogReg baseline):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba2c7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.28 Best weighted F1: 0.5899422344742793\n"
     ]
    }
   ],
   "source": [
    "proba_val = baseline_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    pred = (proba_val >= t).astype(int)\n",
    "    f1s.append(f1_score(y_val, pred, sample_weight=w_val, zero_division=0))\n",
    "\n",
    "best_idx = int(np.argmax(f1s))\n",
    "best_t = float(thresholds[best_idx])\n",
    "best_f1 = float(f1s[best_idx])\n",
    "\n",
    "print(\"Best threshold:\", best_t, \"Best weighted F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c96f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.49672579        nan 0.41100568        nan 0.49950141        nan\n",
      " 0.41133958        nan 0.49616694        nan 0.41263459        nan\n",
      " 0.49556921        nan 0.41197539        nan 0.49740965        nan\n",
      " 0.41269444        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params: {'logreg__C': 0.3, 'logreg__class_weight': None, 'logreg__penalty': 'l2'}\n",
      "Best CV F1: 0.49950140658498005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suzreal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "f1_weighted_scorer = make_scorer(f1_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'logreg__C': [0.1, 0.3, 1.0, 3.0, 10.0],\n",
    "    'logreg__penalty': ['l2', 'l1'],\n",
    "    'logreg__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=baseline_model,param_grid=param_grid,scoring=f1_weighted_scorer, \n",
    "    cv=5,n_jobs=-1,verbose=1)\n",
    "\n",
    "# IMPORTANT: pass weights so each fold training is weighted\n",
    "grid.fit(X_train, y_train, logreg__sample_weight=w_train)\n",
    "\n",
    "print('\\nBest params:', grid.best_params_)\n",
    "print('Best CV F1:', grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02211b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted validation metrics (LogReg with threshold tune):\n",
      "accuracy : 0.9475604074751891\n",
      "precision: 0.5621708969064181\n",
      "recall   : 0.6177203237249969\n",
      "f1       : 0.5886379733209084\n",
      "roc_auc  : 0.9442704549355191\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[31347885.73000008  1006553.46      ]\n",
      " [  799815.65        1292410.8       ]]\n"
     ]
    }
   ],
   "source": [
    "proba_val = best_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.28).astype(int) # -> the best threshold we find before\n",
    "\n",
    "print(\"\\nWeighted validation metrics (LogReg with threshold tune):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4094e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.27 Best weighted F1: 0.588675573346752\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    pred = (proba_val >= t).astype(int)\n",
    "    f1s.append(f1_score(y_val, pred, sample_weight=w_val, zero_division=0))\n",
    "\n",
    "best_idx = int(np.argmax(f1s))\n",
    "best_t = float(thresholds[best_idx])\n",
    "best_f1 = float(f1s[best_idx])\n",
    "\n",
    "print(\"Best threshold:\", best_t, \"Best weighted F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0227580d",
   "metadata": {},
   "source": [
    "The best log-reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23e74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted validation metrics (LogReg Best):\n",
      "accuracy : 0.9468017401407912\n",
      "precision: 0.5549586715196956\n",
      "recall   : 0.626754479659695\n",
      "f1       : 0.588675573346752\n",
      "roc_auc  : 0.9442704549355191\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[31302850.67000009  1051588.52      ]\n",
      " [  780914.15        1311312.3       ]]\n"
     ]
    }
   ],
   "source": [
    "proba_val = best_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.27).astype(int) # -> the best threshold we find before\n",
    "\n",
    "print(\"\\nWeighted validation metrics (LogReg Best):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bfa0a",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f9bf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted validation metrics (xgb baseline):\n",
      "accuracy : 0.9583445801403262\n",
      "precision: 0.7325156020783501\n",
      "recall   : 0.49489560749984857\n",
      "f1       : 0.5907046490446546\n",
      "roc_auc  : 0.9530064617470841\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[31976341.64000006   378097.55      ]\n",
      " [ 1056792.77        1035433.68      ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_col = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_col = [col for col in X_train.columns if col not in numerical_col]\n",
    "\n",
    "numerical_tran = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "cate_tran = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore',  sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    ('num',numerical_tran,numerical_col),\n",
    "    ('cat',cate_tran,categorical_col),],\n",
    "    remainder='drop')\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=600,learning_rate=0.05,max_depth=6,subsample=0.8,colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,min_child_weight=1,objective='binary:logistic',eval_metric='logloss',tree_method='hist',\n",
    "    random_state=42,n_jobs=-1)\n",
    "\n",
    "xgb_model  = Pipeline(steps=[\n",
    "    ('preporcess',preprocess),\n",
    "    ('xgb',xgb)\n",
    "])\n",
    "\n",
    "xgb_model.fit(X_train,y_train,xgb__sample_weight=w_train)\n",
    "\n",
    "\n",
    "proba_val = xgb_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nWeighted validation metrics (xgb baseline):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e65fd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (XGB): 0.35000000000000003\n",
      "Best weighted F1 (XGB): 0.6146306619467286\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "f1s = []\n",
    "for t in thresholds:\n",
    "    pred = (proba_val >= t).astype(int)\n",
    "    f1s.append(f1_score(y_val, pred, sample_weight=w_val, zero_division=0))\n",
    "\n",
    "best_idx = int(np.argmax(f1s))\n",
    "best_t = float(thresholds[best_idx])\n",
    "print('Best threshold (XGB):', best_t)\n",
    "print('Best weighted F1 (XGB):', float(f1s[best_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e13a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted validation metrics (XGB with threshold tune):\n",
      "accuracy : 0.9552375322443544\n",
      "precision: 0.644141644612749\n",
      "recall   : 0.5877052792253922\n",
      "f1       : 0.6146306619467286\n",
      "roc_auc  : 0.9530064617470841\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[31675135.35000006   679303.84      ]\n",
      " [  862613.92        1229612.53      ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "proba_val = xgb_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.35).astype(int)\n",
    "\n",
    "print(\"\\nWeighted validation metrics (XGB with threshold tune):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105887ad",
   "metadata": {},
   "source": [
    "Grid for xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d226bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: {'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8} | best_t: 0.3 | weighted_f1: 0.6154688239623524\n",
      "params: {'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8} | best_t: 0.3 | weighted_f1: 0.6117843544607207\n",
      "params: {'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8} | best_t: 0.36000000000000004 | weighted_f1: 0.6127647959570288\n",
      "params: {'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8} | best_t: 0.29000000000000004 | weighted_f1: 0.603853138445889\n",
      "\n",
      "Best XGB config: {'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8}\n",
      "Best XGB threshold: 0.3\n",
      "Best XGB weighted F1: 0.6154688239623524\n"
     ]
    }
   ],
   "source": [
    "candidates = [\n",
    "    {'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    {'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    {'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "    {'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
    "]\n",
    "\n",
    "best = None\n",
    "\n",
    "for params in candidates:\n",
    "    xgb = XGBClassifier(n_estimators=800,learning_rate=0.05,reg_lambda=1.0,objective='binary:logistic',\n",
    "        eval_metric='logloss',tree_method='hist',random_state=42,n_jobs=-1,**params)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocess', preprocess),\n",
    "        ('xgb', xgb)\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train, xgb__sample_weight=w_train)\n",
    "    p = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        pred = (p >= t).astype(int)\n",
    "        f1s.append(f1_score(y_val, pred, sample_weight=w_val, zero_division=0))\n",
    "\n",
    "    idx = int(np.argmax(f1s))\n",
    "    t_best = float(thresholds[idx])\n",
    "    f1_best = float(f1s[idx])\n",
    "\n",
    "    print('params:', params, '| best_t:', t_best, '| weighted_f1:', f1_best)\n",
    "\n",
    "    if (best is None) or (f1_best > best['f1']):\n",
    "        best = {'model': model, 'params': params, 'threshold': t_best, 'f1': f1_best}\n",
    "\n",
    "print('\\nBest XGB config:', best['params'])\n",
    "print('Best XGB threshold:', best['threshold'])\n",
    "print('Best XGB weighted F1:', best['f1'])\n",
    "best_xgb_model = best['model']\n",
    "best_xgb_threshold = best['threshold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f73834d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted validation metrics (XGB best):\n",
      "accuracy : 0.9520629573481121\n",
      "precision: 0.6001251932845427\n",
      "recall   : 0.6316176339325035\n",
      "f1       : 0.6154688239623524\n",
      "roc_auc  : 0.9538848152081866\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n"
     ]
    }
   ],
   "source": [
    "proba_val = best_xgb_model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >=best_xgb_threshold).astype(int)\n",
    "\n",
    "print(\"\\nWeighted validation metrics (XGB best):\")\n",
    "print(\"accuracy :\", accuracy_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"precision:\", precision_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"recall   :\", recall_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"f1       :\", f1_score(y_val, pred_val, sample_weight=w_val))\n",
    "print(\"roc_auc  :\", roc_auc_score(y_val, proba_val, sample_weight=w_val))\n",
    "\n",
    "cm = confusion_matrix(y_val, pred_val, sample_weight=w_val)\n",
    "print(\"\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47aa5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL TEST (1995) METRICS after refit on all 1994 ===\n",
      "threshold: 0.3\n",
      "accuracy : 0.9485960213365202\n",
      "precision: 0.6168715359516521\n",
      "recall   : 0.626852113732052\n",
      "f1       : 0.6218217789953105\n",
      "roc_auc  : 0.9509990638915975\n",
      "\n",
      "Weighted confusion matrix [[TN, FP],[FN, TP]]:\n",
      "[[1.58314410e+08 4.58476792e+06]\n",
      " [4.39423785e+06 7.38189170e+06]]\n"
     ]
    }
   ],
   "source": [
    "# Refit best model on full 1994 pool\n",
    "best_xgb_model.fit(X_94, y_94, xgb__sample_weight=w_94)\n",
    "\n",
    "# Then run the same test evaluation again\n",
    "proba_test = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "pred_test = (proba_test >= best_xgb_threshold).astype(int)\n",
    "\n",
    "print('\\n=== FINAL TEST (1995) METRICS after refit on all 1994 ===')\n",
    "print('threshold:', best_xgb_threshold)\n",
    "print('accuracy :', accuracy_score(y_test, pred_test, sample_weight=w_test))\n",
    "print('precision:', precision_score(y_test, pred_test, sample_weight=w_test, zero_division=0))\n",
    "print('recall   :', recall_score(y_test, pred_test, sample_weight=w_test, zero_division=0))\n",
    "print('f1       :', f1_score(y_test, pred_test, sample_weight=w_test, zero_division=0))\n",
    "print('roc_auc  :', roc_auc_score(y_test, proba_test, sample_weight=w_test))\n",
    "print('\\nWeighted confusion matrix [[TN, FP],[FN, TP]]:')\n",
    "print(confusion_matrix(y_test, pred_test, sample_weight=w_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
